{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e365047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "# from peft import PeftModel\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "158f49c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbcc19a",
   "metadata": {},
   "source": [
    "# Обученная"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1767acc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "/home/t3fio/miniconda3/envs/jokes/lib/python3.13/site-packages/peft/tuners/tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 1536)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkpath = 'qwen2.5-lora-jokes/v2.0/checkpoint-764_scoutie' #scoutie dataset\n",
    "checkpath = 'qwen2.5-lora-jokes/v2.0/checkpoint-2906_parsed' # parsed dataset\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpath, trust_remote_code=True)\n",
    "# model = PeftModel.from_pretrained(base_model, checkpath)\n",
    "# model = model.merge_and_unload()\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7122909a",
   "metadata": {},
   "source": [
    "# Необученная"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9238614a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     trust_remote_code=True,\n",
    "#     device_map=\"auto\",\n",
    "#     torch_dtype=\"auto\",\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909cc9c9",
   "metadata": {},
   "source": [
    "# Получение анекдотов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a513422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Заходит мужик в шкаф\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Ты генератор шуток, отвечай только с помощью анекдотов.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Заходит бесконечное количество математиков в бар\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Бесконечное число математиков заходит в бар. Первый говорит: «Мне кружку пива!». Второй говорит: «Мне половину кружки пива!» Третий говорит: «Мне четверть кружки пива!» Четвертый говорит: «Мне 1/8 кружки пива!» Бармен:– Да знаю я вас – вам две кружки на всех!\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=256,\n",
    "    num_return_sequences = 5, # Количество ответов\n",
    ")\n",
    "\n",
    "anecdotes = [prompt + '\\n' + tokenizer.batch_decode([\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, [generated_ids[i]])\n",
    "    ], skip_special_tokens=True)[0] for i in range(len(generated_ids))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5fd8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка модели\n",
    "bert = DistilBertForSequenceClassification.from_pretrained('funny_jokes_classifier.model')\n",
    "bert_tokenizer = DistilBertTokenizer.from_pretrained('funny_jokes_classifier.tokenizer')\n",
    "MAX_LEN= 128\n",
    "# Предсказание на новом тексте\n",
    "def predict_funny_score(model, joke, tokenizer):\n",
    "    model.to('cpu')\n",
    "    # Токенизация\n",
    "    encoded_joke = tokenizer.encode_plus(\n",
    "        joke,\n",
    "        max_length=MAX_LEN,\n",
    "        add_special_tokens=True,\n",
    "        return_token_type_ids=False,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    input_ids = encoded_joke['input_ids'].to('cpu')\n",
    "    attention_mask = encoded_joke['attention_mask'].to('cpu')\n",
    "\n",
    "    # Предсказание\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask)\n",
    "\n",
    "    # Получаем сырое предсказание\n",
    "    prediction = output.logits.squeeze()\n",
    "\n",
    "    return 1 / (1 + np.exp(-prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2101ec3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9479/2634738824.py:30: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  return 1 / (1 + np.exp(-prediction))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Шутка: \"Заходит мужик в шкаф\n",
      "Мужик вошел в шкаф и увидел там лампочку....\"\n",
      "Оценка смешнявости: 0.46\n",
      "\n",
      "Шутка: \"Заходит мужик в шкаф\n",
      "Заводской номер 2345...\"\n",
      "Оценка смешнявости: 0.41\n",
      "\n",
      "Шутка: \"Заходит мужик в шкаф\n",
      "Здесь нет ни одной женщины!...\"\n",
      "Оценка смешнявости: 0.42\n",
      "\n",
      "Шутка: \"Заходит мужик в шкаф\n",
      "Кто-нибудь может объяснить мне, почему я не могу найти свою жену?...\"\n",
      "Оценка смешнявости: 0.56\n",
      "\n",
      "Шутка: \"Заходит мужик в шкаф\n",
      "Мужик вошел в шкаф. Навстречу ему стоит женщина. Мужик говорит: - Привет, ты что там делаешь? Жена: - Я твоя жена. Мужик: - А мне какая она?...\"\n",
      "Оценка смешнявости: 0.60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for anecdote in anecdotes:\n",
    "    score = predict_funny_score(bert, anecdote, bert_tokenizer)\n",
    "    print(f'Шутка: \"{anecdote[:]}...\"\\nОценка смешнявости: {score:.2f}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jokes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
